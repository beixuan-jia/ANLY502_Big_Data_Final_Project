{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-66-237.ec2.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fae0336ee90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"s3://miaowang1009/ANLY502_Final/df.parquet/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GLOBALEVENTID: string (nullable = true)\n",
      " |-- SQLDATE: date (nullable = true)\n",
      " |-- MonthYear: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- FractionDate: string (nullable = true)\n",
      " |-- Actor1Code: string (nullable = true)\n",
      " |-- Actor1Name: string (nullable = true)\n",
      " |-- Actor1CountryCode: string (nullable = true)\n",
      " |-- Actor1KnownGroupCode: string (nullable = true)\n",
      " |-- Actor1EthnicCode: string (nullable = true)\n",
      " |-- Actor1Religion1Code: string (nullable = true)\n",
      " |-- Actor1Religion2Code: string (nullable = true)\n",
      " |-- Actor1Type1Code: string (nullable = true)\n",
      " |-- Actor1Type2Code: string (nullable = true)\n",
      " |-- Actor1Type3Code: string (nullable = true)\n",
      " |-- Actor2Code: string (nullable = true)\n",
      " |-- Actor2Name: string (nullable = true)\n",
      " |-- Actor2CountryCode: string (nullable = true)\n",
      " |-- Actor2KnownGroupCode: string (nullable = true)\n",
      " |-- Actor2EthnicCode: string (nullable = true)\n",
      " |-- Actor2Religion1Code: string (nullable = true)\n",
      " |-- Actor2Religion2Code: string (nullable = true)\n",
      " |-- Actor2Type1Code: string (nullable = true)\n",
      " |-- Actor2Type2Code: string (nullable = true)\n",
      " |-- Actor2Type3Code: string (nullable = true)\n",
      " |-- IsRootEvent: string (nullable = true)\n",
      " |-- EventCode: string (nullable = true)\n",
      " |-- EventBaseCode: string (nullable = true)\n",
      " |-- EventRootCode: string (nullable = true)\n",
      " |-- QuadClass: string (nullable = true)\n",
      " |-- GoldsteinScale: float (nullable = true)\n",
      " |-- NumMentions: integer (nullable = true)\n",
      " |-- NumSources: integer (nullable = true)\n",
      " |-- NumArticles: integer (nullable = true)\n",
      " |-- AvgTone: float (nullable = true)\n",
      " |-- Actor1Geo_Type: string (nullable = true)\n",
      " |-- Actor1Geo_FullName: string (nullable = true)\n",
      " |-- Actor1Geo_CountryCode: string (nullable = true)\n",
      " |-- Actor1Geo_ADM1Code: string (nullable = true)\n",
      " |-- Actor1Geo_Lat: float (nullable = true)\n",
      " |-- Actor1Geo_Long: float (nullable = true)\n",
      " |-- Actor1Geo_FeatureID: string (nullable = true)\n",
      " |-- Actor2Geo_Type: string (nullable = true)\n",
      " |-- Actor2Geo_FullName: string (nullable = true)\n",
      " |-- Actor2Geo_CountryCode: string (nullable = true)\n",
      " |-- Actor2Geo_ADM1Code: string (nullable = true)\n",
      " |-- Actor2Geo_Lat: string (nullable = true)\n",
      " |-- Actor2Geo_Long: string (nullable = true)\n",
      " |-- Actor2Geo_FeatureID: string (nullable = true)\n",
      " |-- ActionGeo_Type: string (nullable = true)\n",
      " |-- ActionGeo_FullName: string (nullable = true)\n",
      " |-- ActionGeo_CountryCode: string (nullable = true)\n",
      " |-- ActionGeo_ADM1Code: string (nullable = true)\n",
      " |-- ActionGeo_Lat: string (nullable = true)\n",
      " |-- ActionGeo_Long: string (nullable = true)\n",
      " |-- ActionGeo_FeatureID: string (nullable = true)\n",
      " |-- DATEADDED: string (nullable = true)\n",
      " |-- SOURCEURL: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = df.select(df.AvgTone, df.NumArticles,df.NumMentions, df.ActionGeo_Type, df.EventRootCode, df.QuadClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+--------------+-------------+---------+----------+----------+\n",
      "|    AvgTone|NumArticles|NumMentions|ActionGeo_Type|EventRootCode|QuadClass|AvgToneBin|AvgToneTag|\n",
      "+-----------+-----------+-----------+--------------+-------------+---------+----------+----------+\n",
      "|  0.7025761|         10|         10|             4|           04|        1|       1.0|  Positive|\n",
      "|-0.73937154|          6|          6|             5|           01|        1|       0.0|   Negtive|\n",
      "|-0.73937154|          2|          2|             4|           01|        1|       0.0|   Negtive|\n",
      "|-0.73937154|          2|          2|             1|           04|        1|       0.0|   Negtive|\n",
      "|  0.7025761|          2|          2|             4|           04|        1|       1.0|  Positive|\n",
      "|-0.73937154|          6|          6|             4|           03|        1|       0.0|   Negtive|\n",
      "|  0.7025761|         10|         10|             4|           04|        1|       1.0|  Positive|\n",
      "| -2.1311476|          3|          3|             4|           17|        4|       0.0|   Negtive|\n",
      "| -2.1311476|          6|          6|             4|           17|        4|       0.0|   Negtive|\n",
      "| -2.1311476|          1|          1|             4|           17|        4|       0.0|   Negtive|\n",
      "| -3.4739454|        180|        180|             4|           01|        1|       0.0|   Negtive|\n",
      "|  -7.402101|        965|        995|             0|           01|        1|       0.0|   Negtive|\n",
      "| -6.5946918|         14|         14|             1|           13|        3|       0.0|   Negtive|\n",
      "| -2.2292848|        136|        136|             2|           12|        3|       0.0|   Negtive|\n",
      "|  3.3175356|          5|          5|             4|           03|        1|       1.0|  Positive|\n",
      "|  3.3175356|          3|          3|             4|           03|        1|       1.0|  Positive|\n",
      "| -2.7027028|          5|          5|             3|           07|        2|       0.0|   Negtive|\n",
      "|  -4.130409|         19|         19|             4|           02|        1|       0.0|   Negtive|\n",
      "|  -4.130409|         39|         39|             3|           02|        1|       0.0|   Negtive|\n",
      "| -2.1802325|          2|          2|             4|           02|        1|       0.0|   Negtive|\n",
      "+-----------+-----------+-----------+--------------+-------------+---------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "bucketizer = Bucketizer(splits=[ -100, 0, 100, float('Inf') ],inputCol=\"AvgTone\", outputCol=\"AvgToneBin\")\n",
    "df_feat = bucketizer.setHandleInvalid(\"keep\").transform(df_feat)\n",
    "\n",
    "#df_buck.show()\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "t = {0.0:\"Negtive\", 1.0:\"Positive\"}\n",
    "udf_foo = udf(lambda x: t[x], StringType())\n",
    "df_feat = df_feat.withColumn(\"AvgToneTag\", udf_foo(\"AvgToneBin\"))\n",
    "df_feat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NumArticles: integer (nullable = true)\n",
      " |-- NumMentions: integer (nullable = true)\n",
      " |-- ActionGeo_Type: string (nullable = true)\n",
      " |-- EventRootCode: string (nullable = true)\n",
      " |-- QuadClass: string (nullable = true)\n",
      " |-- AvgToneBin: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_feats = df_feat.drop('AvgTone').drop('AvgToneTag')\n",
    "df_feats.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_data = df_feats.randomSplit([0.8,0.18,0.02],24)\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]\n",
    "predicted_data = splitted_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "StringIndexer_label = StringIndexer(inputCol=\"AvgToneBin\", outputCol = \"label\")\n",
    "StringIndexer_AGT = StringIndexer(inputCol=\"ActionGeo_Type\", outputCol = \"ActionGeo_Type_IX\")\n",
    "StringIndexer_ERC = StringIndexer(inputCol=\"EventRootCode\", outputCol = \"EventRootCode_IX\")\n",
    "StringIndexer_QC = StringIndexer(inputCol=\"QuadClass\", outputCol = \"QuadClass_IX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0', '1.0']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_label_fit = StringIndexer(inputCol=\"AvgToneBin\", outputCol = \"label\").fit(df_feats)\n",
    "si_label_fit.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a feature vector by combining all features together using the vectorAssembler method:\n",
    "\n",
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols=[\"ActionGeo_Type_IX\", \"EventRootCode_IX\", \"QuadClass_IX\", \"NumArticles\",\"NumMentions\"],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model\n",
    "\n",
    "# define estimators \n",
    "rf = RandomForestClassifier(labelCol='label', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol='prediction', \n",
    "                               outputCol='predictedLabel', \n",
    "                               labels=StringIndexer_label.fit(df_feats).labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline. A pipeline consists of transformers and an estimator.\n",
    "\n",
    "pipeline_rf = Pipeline(stages=[StringIndexer_label,\n",
    "                              StringIndexer_AGT,\n",
    "                              StringIndexer_ERC,\n",
    "                              StringIndexer_QC,\n",
    "                              vectorAssembler_features,\n",
    "                              rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NumArticles: integer (nullable = true)\n",
      " |-- NumMentions: integer (nullable = true)\n",
      " |-- ActionGeo_Type: string (nullable = true)\n",
      " |-- EventRootCode: string (nullable = true)\n",
      " |-- QuadClass: string (nullable = true)\n",
      " |-- AvgToneBin: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = pipeline_rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_rf.transform(test_data)\n",
    "evaluatorRF = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluatorRF.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.566251\n",
      "Test Error = 0.433749\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = %g\" % accuracy)\n",
    "print(\"Test Error = %g\" % (1.0-accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------+-------------+---------+----------+-----+-----------------+----------------+------------+--------------------+--------------------+--------------------+----------+--------------+\n",
      "|NumArticles|NumMentions|ActionGeo_Type|EventRootCode|QuadClass|AvgToneBin|label|ActionGeo_Type_IX|EventRootCode_IX|QuadClass_IX|            features|       rawPrediction|         probability|prediction|predictedLabel|\n",
      "+-----------+-----------+--------------+-------------+---------+----------+-----+-----------------+----------------+------------+--------------------+--------------------+--------------------+----------+--------------+\n",
      "|          1|          1|             0|           02|        1|       0.0|  0.0|              4.0|             4.0|         0.0|[4.0,4.0,0.0,1.0,...|[13.2873127890885...|[0.66436563945442...|       0.0|           0.0|\n",
      "|          1|          1|             0|           03|        1|       1.0|  1.0|              4.0|             3.0|         0.0|[4.0,3.0,0.0,1.0,...|[12.6338392561005...|[0.63169196280502...|       0.0|           0.0|\n",
      "|          1|          1|             0|           05|        1|       1.0|  1.0|              4.0|             2.0|         0.0|[4.0,2.0,0.0,1.0,...|[10.2908018491547...|[0.51454009245773...|       0.0|           0.0|\n",
      "|          1|          1|             0|           05|        1|       1.0|  1.0|              4.0|             2.0|         0.0|[4.0,2.0,0.0,1.0,...|[10.2908018491547...|[0.51454009245773...|       0.0|           0.0|\n",
      "|          1|          1|             0|           05|        1|       1.0|  1.0|              4.0|             2.0|         0.0|[4.0,2.0,0.0,1.0,...|[10.2908018491547...|[0.51454009245773...|       0.0|           0.0|\n",
      "|          1|          1|             0|           19|        4|       0.0|  0.0|              4.0|             5.0|         1.0|[4.0,5.0,1.0,1.0,...|[16.8580590544670...|[0.84290295272335...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "|          1|          1|             1|           01|        1|       0.0|  0.0|              1.0|             1.0|         0.0|[1.0,1.0,0.0,1.0,...|[13.4522187566805...|[0.67261093783402...|       0.0|           0.0|\n",
      "+-----------+-----------+--------------+-------------+---------+----------+-----+-----------------+----------------+------------+--------------------+--------------------+--------------------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'IndexToString' object has no attribute 'featureImportances'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-ace37adc4d46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatureImportances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'IndexToString' object has no attribute 'featureImportances'"
     ]
    }
   ],
   "source": [
    "importances = model_rf.stages[-1].featureImportances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(stages=[StringIndexer_AGT, StringIndexer_ERC, StringIndexer_QC, StringIndexer_label, \n",
    "                               vectorAssembler_features, \n",
    "                               lr, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = pipeline_lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator().setLabelCol(\"label\").setRawPredictionCol(\"rawPrediction\").setMetricName(\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------+-------------+---------+----------+-----+-----------------+----------------+------------+--------------------+--------------------+--------------------+----------+--------------+\n",
      "|NumArticles|NumMentions|ActionGeo_Type|EventRootCode|QuadClass|AvgToneBin|label|ActionGeo_Type_IX|EventRootCode_IX|QuadClass_IX|            features|       rawPrediction|         probability|prediction|predictedLabel|\n",
      "+-----------+-----------+--------------+-------------+---------+----------+-----+-----------------+----------------+------------+--------------------+--------------------+--------------------+----------+--------------+\n",
      "|          1|          1|             0|           02|        1|       0.0|  0.0|              4.0|             4.0|         0.0|[4.0,4.0,0.0,1.0,...|[13.2873127890885...|[0.66436563945442...|       0.0|           0.0|\n",
      "|          1|          1|             0|           03|        1|       1.0|  1.0|              4.0|             3.0|         0.0|[4.0,3.0,0.0,1.0,...|[12.6338392561005...|[0.63169196280502...|       0.0|           0.0|\n",
      "|          1|          1|             0|           05|        1|       1.0|  1.0|              4.0|             2.0|         0.0|[4.0,2.0,0.0,1.0,...|[10.2908018491547...|[0.51454009245773...|       0.0|           0.0|\n",
      "|          1|          1|             0|           05|        1|       1.0|  1.0|              4.0|             2.0|         0.0|[4.0,2.0,0.0,1.0,...|[10.2908018491547...|[0.51454009245773...|       0.0|           0.0|\n",
      "|          1|          1|             0|           05|        1|       1.0|  1.0|              4.0|             2.0|         0.0|[4.0,2.0,0.0,1.0,...|[10.2908018491547...|[0.51454009245773...|       0.0|           0.0|\n",
      "+-----------+-----------+--------------+-------------+---------+----------+-----+-----------------+----------------+------------+--------------------+--------------------+--------------------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_lr = model_lr.transform(test_data)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_lr = evaluator.evaluate(predictions_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.6141103430789744\n"
     ]
    }
   ],
   "source": [
    "print('Test Area Under ROC', evaluator.evaluate(predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.61411\n",
      "Test Error = 0.38589\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = %g\" % accuracy_lr)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save models to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.write().save('s3://miaowang1009/ANLY502_Final/model_rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr.write().save('s3://miaowang1009/ANLY502_Final/model_lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats = df_feat.drop('AvgTone').drop('AvgToneTag')\n",
    "df_feats.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression(labelCol='Avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
